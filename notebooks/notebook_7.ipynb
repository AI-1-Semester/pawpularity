{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Script to create a CSV file for the cats vs dogs dataset\n",
    "#\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Directory paths\n",
    "cats_dir = \"../data/train/cnn_train_images/cats\"\n",
    "dogs_dir = \"../data/train/cnn_train_images/dogs\"\n",
    "csv_dir = '../data/train/cnn_train_images'\n",
    "\n",
    "# File path within the folder\n",
    "csv_file_path = os.path.join(csv_dir, \"cats_vs_dogs_train.csv\")\n",
    "\n",
    "# List to store image paths and labels\n",
    "data = []\n",
    "\n",
    "# Process cats images\n",
    "for filename in os.listdir(cats_dir):\n",
    "    filepath = os.path.join(cats_dir, filename)\n",
    "    \n",
    "    # Splitting the string at the first occurrence of '.'\n",
    "    id_number = filename.split('.', 1)\n",
    "\n",
    "    # Keeping only the part before the first '.'\n",
    "    id = id_number[0]\n",
    "\n",
    "    data.append([id, 1, 0])  # Label 1 for cat\n",
    "\n",
    "# Process dogs images\n",
    "for filename in os.listdir(dogs_dir):\n",
    "    filepath = os.path.join(dogs_dir, filename)\n",
    "            \n",
    "    # Splitting the string at the first occurrence of '.'\n",
    "    id_number = filename.split('.', 1)\n",
    "\n",
    "    # Keeping only the part before the first '.'\n",
    "    id = id_number[0]\n",
    "\n",
    "    data.append([id, 0, 1])  # Label 0 for non-hotdog\n",
    "\n",
    "# Shuffle the data\n",
    "import random\n",
    "random.shuffle(data)\n",
    "\n",
    "# Write data to CSV file\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\"Id\", \"Cat\", \"Dog\"])\n",
    "    csvwriter.writerows(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Append labels from one CSV file to another (combine other train labels with cats vs dogs labels)\n",
    "#\n",
    "\n",
    "# Function to read CSV file and return a dictionary where keys are IDs\n",
    "def read_csv_to_dict(file_path):\n",
    "    data_dict = {}\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            data_dict[row['Id']] = row\n",
    "    return data_dict\n",
    "\n",
    "# Paths to the CSV files\n",
    "csv1_path = \"../data/train/train.csv\"\n",
    "csv2_path = \"../data/train/cats_vs_dogs_train.csv\"\n",
    "\n",
    "# Read CSV files into dictionaries\n",
    "csv1_data = read_csv_to_dict(csv1_path)\n",
    "csv2_data = read_csv_to_dict(csv2_path)\n",
    "\n",
    "# Append labels from CSV1 to CSV2 if IDs match\n",
    "for id, row in csv2_data.items():\n",
    "    if id in csv1_data:\n",
    "        csv2_data[id].update(csv1_data[id])\n",
    "\n",
    "# Write combined data to a new CSV file\n",
    "combined_csv_path = \"../data/train/cats_vs_dogs_train.csv\"\n",
    "with open(combined_csv_path, \"w\", newline='') as csvfile:\n",
    "    fieldnames = list(csv2_data.values())[0].keys()\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(csv2_data.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "# Step 1: Prepare the Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.data.iloc[idx, 0]) + \".jpg\"\n",
    "        image = Image.open(img_name)\n",
    "        label = self.data.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = CustomDataset(csv_file='../data/train/cnn_train_images/cats_vs_dogs_train.csv',\n",
    "                              root_dir='../data/train/cnn_train_images/',\n",
    "                              transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the CNN Architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(128 * 6 * 6, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)  # 2 classes: Cat and Dog\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 128 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6937\n",
      "Epoch [2/100], Loss: 0.6779\n",
      "Epoch [3/100], Loss: 0.7166\n",
      "Epoch [4/100], Loss: 0.6884\n",
      "Epoch [5/100], Loss: 0.6987\n",
      "Epoch [6/100], Loss: 0.6912\n",
      "Epoch [7/100], Loss: 0.6879\n",
      "Epoch [8/100], Loss: 0.6931\n",
      "Epoch [9/100], Loss: 0.7325\n",
      "Epoch [10/100], Loss: 0.6979\n",
      "Epoch [11/100], Loss: 0.6731\n",
      "Epoch [12/100], Loss: 0.6342\n",
      "Epoch [13/100], Loss: 0.6120\n",
      "Epoch [14/100], Loss: 0.5294\n",
      "Epoch [15/100], Loss: 0.4541\n",
      "Epoch [16/100], Loss: 0.5888\n",
      "Epoch [17/100], Loss: 0.4367\n",
      "Epoch [18/100], Loss: 0.3118\n",
      "Epoch [19/100], Loss: 0.2876\n",
      "Epoch [20/100], Loss: 0.5139\n",
      "Epoch [21/100], Loss: 0.3416\n",
      "Epoch [22/100], Loss: 0.9613\n",
      "Epoch [23/100], Loss: 0.8490\n",
      "Epoch [24/100], Loss: 0.3861\n",
      "Epoch [25/100], Loss: 0.3461\n",
      "Epoch [26/100], Loss: 0.2692\n",
      "Epoch [27/100], Loss: 0.7558\n",
      "Epoch [28/100], Loss: 0.3385\n",
      "Epoch [29/100], Loss: 0.2045\n",
      "Epoch [30/100], Loss: 0.1172\n",
      "Epoch [31/100], Loss: 0.1373\n",
      "Epoch [32/100], Loss: 0.1479\n",
      "Epoch [33/100], Loss: 0.0784\n",
      "Epoch [34/100], Loss: 0.0241\n",
      "Epoch [35/100], Loss: 0.0266\n",
      "Epoch [36/100], Loss: 0.0592\n",
      "Epoch [37/100], Loss: 0.0122\n",
      "Epoch [38/100], Loss: 0.1019\n",
      "Epoch [39/100], Loss: 0.0754\n",
      "Epoch [40/100], Loss: 0.0085\n",
      "Epoch [41/100], Loss: 0.0456\n",
      "Epoch [42/100], Loss: 0.0051\n",
      "Epoch [43/100], Loss: 0.0025\n",
      "Epoch [44/100], Loss: 0.0049\n",
      "Epoch [45/100], Loss: 0.0086\n",
      "Epoch [46/100], Loss: 0.0037\n",
      "Epoch [47/100], Loss: 0.0015\n",
      "Epoch [48/100], Loss: 0.0014\n",
      "Epoch [49/100], Loss: 0.0019\n",
      "Epoch [50/100], Loss: 0.0039\n",
      "Epoch [51/100], Loss: 0.0018\n",
      "Epoch [52/100], Loss: 0.0000\n",
      "Epoch [53/100], Loss: 0.0004\n",
      "Epoch [54/100], Loss: 0.0003\n",
      "Epoch [55/100], Loss: 0.0016\n",
      "Epoch [56/100], Loss: 0.0001\n",
      "Epoch [57/100], Loss: 0.0003\n",
      "Epoch [58/100], Loss: 0.0009\n",
      "Epoch [59/100], Loss: 0.0008\n",
      "Epoch [60/100], Loss: 0.0008\n",
      "Epoch [61/100], Loss: 0.0001\n",
      "Epoch [62/100], Loss: 0.0001\n",
      "Epoch [63/100], Loss: 0.0015\n",
      "Epoch [64/100], Loss: 0.0007\n",
      "Epoch [65/100], Loss: 0.0004\n",
      "Epoch [66/100], Loss: 0.0000\n",
      "Epoch [67/100], Loss: 0.0002\n",
      "Epoch [68/100], Loss: 0.0005\n",
      "Epoch [69/100], Loss: 0.0006\n",
      "Epoch [70/100], Loss: 0.0008\n",
      "Epoch [71/100], Loss: 0.0003\n",
      "Epoch [72/100], Loss: 0.0002\n",
      "Epoch [73/100], Loss: 0.0003\n",
      "Epoch [74/100], Loss: 0.0002\n",
      "Epoch [75/100], Loss: 0.0001\n",
      "Epoch [76/100], Loss: 0.0006\n",
      "Epoch [77/100], Loss: 0.0000\n",
      "Epoch [78/100], Loss: 0.0001\n",
      "Epoch [79/100], Loss: 0.0001\n",
      "Epoch [80/100], Loss: 0.0003\n",
      "Epoch [81/100], Loss: 0.0002\n",
      "Epoch [82/100], Loss: 0.0003\n",
      "Epoch [83/100], Loss: 0.0004\n",
      "Epoch [84/100], Loss: 0.0004\n",
      "Epoch [85/100], Loss: 0.0002\n",
      "Epoch [86/100], Loss: 0.0002\n",
      "Epoch [87/100], Loss: 0.0003\n",
      "Epoch [88/100], Loss: 0.0004\n",
      "Epoch [89/100], Loss: 0.0001\n",
      "Epoch [90/100], Loss: 0.0004\n",
      "Epoch [91/100], Loss: 0.0002\n",
      "Epoch [92/100], Loss: 0.0002\n",
      "Epoch [93/100], Loss: 0.0001\n",
      "Epoch [94/100], Loss: 0.0000\n",
      "Epoch [95/100], Loss: 0.0001\n",
      "Epoch [96/100], Loss: 0.0003\n",
      "Epoch [97/100], Loss: 0.0002\n",
      "Epoch [98/100], Loss: 0.0001\n",
      "Epoch [99/100], Loss: 0.0001\n",
      "Epoch [100/100], Loss: 0.0001\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the Model\n",
    "\n",
    "# WINDOWS: Device will determine whether to run the training on GPU or CPU.\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# MAC: Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "print('Finished Training')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pawpularityVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
